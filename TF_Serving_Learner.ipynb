{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkd-AMFUeRuC"
      },
      "source": [
        "<h2 align=\"center\"> Deploy Models with TensorFlow Serving and Docker</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivsT42oDeRuG"
      },
      "source": [
        " Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQhSNW-CZUZh"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ucyS8wIeRuJ"
      },
      "outputs": [],
      "source": [
        "def load_dataset(file_path,num_samples):\n",
        "  df=pd.read_csv(file_path,usecols=[6,9],nrows=num_samples)\n",
        "  df.columns=['rating','title']\n",
        "  \n",
        "  text=df['title'].tolist()\n",
        "  text=[str(t).encode('ascii','replace') for t in text]\n",
        "  text=np.array(text,dtype=object)[:]\n",
        "\n",
        "  labels=df['rating'].tolist()\n",
        "  labels=[1 if i>=4 else 0 if i==3 else -1 for i in labels]\n",
        "  labels=np.array(pd.get_dummies(labels),dtype=int)[:]\n",
        "  return labels,text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Glsh2slneRuJ"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slrIU84ReRuK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulDaQ-pMeRuK"
      },
      "source": [
        "### Build the Classification Model using TF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xy-WHjVeRuK"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "\n",
        "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\n",
        "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\n",
        "def get_model():\n",
        "  hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", output_shape=[128],\n",
        "                           input_shape=[], dtype=tf.string)  #Token based text embedding trained on English Google News 7B corpus\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(hub_layer)\n",
        "  model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQhm_G41eRuL",
        "outputId": "fd55970f-6be9-42e9-d9eb-66a25248d3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4.45802003e-01 -1.66882738e-01 -1.25613630e-01  2.52814777e-02\n",
            "   2.38615081e-01  3.64428103e-01 -1.17987983e-01  2.41861641e-01\n",
            "  -1.53490186e-01 -9.13521275e-03  3.87853459e-02  3.58332172e-02\n",
            "  -1.09570436e-01  9.61917341e-02  2.08671808e-01  2.35103816e-02\n",
            "   3.35804045e-01 -4.76312637e-03 -2.15895921e-02 -7.05669448e-03\n",
            "  -3.43162902e-02 -3.04552257e-01 -8.96364450e-03 -1.22085251e-02\n",
            "  -8.14640373e-02 -3.58781815e-01  3.11557241e-02  2.37879902e-02\n",
            "  -6.94732219e-02 -1.98291108e-01 -6.18666001e-02  2.02120781e-01\n",
            "  -3.05522382e-02  1.56283751e-02  1.52608529e-01 -7.16896206e-02\n",
            "  -1.68161184e-01 -1.63737293e-02 -1.99878365e-01  6.45219088e-02\n",
            "   4.91093919e-02  2.15945631e-01  6.72324374e-02 -7.01343119e-02\n",
            "   1.17598206e-01 -2.33126760e-01  5.04524931e-02  2.55567849e-01\n",
            "   1.99451461e-01 -5.53790480e-03]\n",
            " [ 1.68188766e-01  1.62894666e-01  2.60049254e-01  9.11546946e-02\n",
            "  -1.17276795e-01 -2.36244053e-02  1.14455312e-01  1.48555547e-01\n",
            "  -2.24658251e-01 -9.29626450e-03 -1.55883431e-01 -1.18474215e-01\n",
            "   2.98978817e-02 -4.91420254e-02  2.65103638e-01 -1.26332611e-01\n",
            "  -1.20221369e-01  2.03847885e-05 -3.64884846e-02 -2.18592003e-01\n",
            "  -1.52689546e-01 -2.25912631e-02 -3.62459570e-02 -7.04980046e-02\n",
            "  -2.44523406e-01  9.35696661e-02 -2.40691632e-01 -7.04346597e-03\n",
            "   3.71699259e-02 -2.00196773e-01 -2.13137031e-01  1.82656944e-01\n",
            "  -1.82519615e-01 -1.66350454e-01 -1.73377335e-01  7.46382326e-02\n",
            "   2.86008328e-01 -2.49488540e-02 -3.74140032e-03 -7.38649815e-03\n",
            "  -1.54502718e-02  2.03128114e-01 -8.55530724e-02  1.52320907e-01\n",
            "  -3.16466153e-01 -2.84579068e-01 -1.66612774e-01 -2.20954925e-01\n",
            "   6.77508414e-02  3.14488932e-02]\n",
            " [ 2.91283637e-01  1.29606932e-01  3.15558553e-01  2.36243993e-01\n",
            "  -7.60439709e-02 -2.11477071e-01  1.11202467e-02 -2.97003929e-02\n",
            "  -3.13532591e-01 -6.62729517e-02  5.61450906e-02 -9.26792696e-02\n",
            "   1.12281002e-01 -1.21784233e-01 -1.71650723e-01 -4.10723174e-03\n",
            "   5.12647480e-02  7.03312978e-02  2.94495430e-02  2.59202510e-01\n",
            "  -1.73323810e-01 -1.28122140e-03 -5.32643124e-02  4.66798656e-02\n",
            "   1.80393830e-01 -2.85028547e-01  1.40276728e-02  1.14847660e-01\n",
            "  -1.45111859e-01  9.69678164e-02 -4.76637706e-02  5.87643608e-02\n",
            "   4.64336760e-02 -2.32970834e-01  7.07191229e-03 -1.69134233e-02\n",
            "  -3.16125229e-02 -1.54181436e-01 -2.74882875e-02 -1.58048868e-01\n",
            "  -1.10039271e-01  3.03260274e-02  8.09711870e-03  9.68564749e-02\n",
            "   4.43438441e-02  1.25747904e-01  5.64634353e-02 -4.53963913e-02\n",
            "   2.30751447e-02  1.84860066e-01]], shape=(3, 50), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\")\n",
        "embeddings = embed([\"tounsi 7or mala la3b\", \"this is my project \",\"testing the embd\"])\n",
        "print(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h__AXclneRuM"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "\n",
        "def train(EPOCHS=5,b_size=32,train_file='/content/train (1).csv',val_file='/content/test (1).csv'):\n",
        "  working_dir=os.getcwd()\n",
        "  y_train,x_train=load_dataset(train_file,500000)\n",
        "  y_val,x_val=load_dataset(val_file,50000)\n",
        "\n",
        "  model=get_model()\n",
        "  model.fit(x_train,y_train,batch_size=b_size,epochs=EPOCHS,verbose=1,\n",
        "            validation_data=(x_val,y_val),\n",
        "            callbacks=[tf.keras.callbacks.ModelCheckpoint(os.path.join(working_dir,'model_checkpoint'),\n",
        "                                                          monitor='val_loss',vebose=1,save_best_model=True,\n",
        "                                                          save_weights_only=False,mode='auto')])\n",
        "  return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7_S6344eRuN"
      },
      "source": [
        "Train and Export Model as Protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EnbV2XFeRuN",
        "outputId": "9beb2332-f515-442c-8509-44cba8fc8653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 128)               124642688 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,653,123\n",
            "Trainable params: 10,435\n",
            "Non-trainable params: 124,642,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "8877/8883 [============================>.] - ETA: 0s - loss: 0.5100 - accuracy: 0.8084INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8883/8883 [==============================] - 41s 5ms/step - loss: 0.5100 - accuracy: 0.8084 - val_loss: 0.4966 - val_accuracy: 0.8119\n",
            "Epoch 2/5\n",
            "8880/8883 [============================>.] - ETA: 0s - loss: 0.4878 - accuracy: 0.8160INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8883/8883 [==============================] - 44s 5ms/step - loss: 0.4878 - accuracy: 0.8160 - val_loss: 0.4894 - val_accuracy: 0.8147\n",
            "Epoch 3/5\n",
            "8876/8883 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.8189INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8883/8883 [==============================] - 39s 4ms/step - loss: 0.4786 - accuracy: 0.8189 - val_loss: 0.4842 - val_accuracy: 0.8172\n",
            "Epoch 4/5\n",
            "8874/8883 [============================>.] - ETA: 0s - loss: 0.4717 - accuracy: 0.8213INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8883/8883 [==============================] - 39s 4ms/step - loss: 0.4717 - accuracy: 0.8213 - val_loss: 0.4768 - val_accuracy: 0.8192\n",
            "Epoch 5/5\n",
            "8874/8883 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8233INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model_checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8883/8883 [==============================] - 41s 5ms/step - loss: 0.4661 - accuracy: 0.8233 - val_loss: 0.4792 - val_accuracy: 0.8193\n",
            "INFO:tensorflow:Assets written to: amazon_review/1649202398/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: amazon_review/1649202398/assets\n"
          ]
        }
      ],
      "source": [
        "#%%writefile -a train.py\n",
        "\n",
        "def export_model(model,base_path=\"amazon_review/\"):\n",
        "  path=os.path.join(base_path,str(int(time.time())))\n",
        "  tf.saved_model.save(model,path)\n",
        "if __name__=='__main__':\n",
        "  model=train()\n",
        "  export_model(model)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8-qVEsNeRuO"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se12nhMEeRuO",
        "outputId": "e9cd36ab-18a6-452c-f06a-9e0d05209be7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18521847, 0.08230737, 0.7324742 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "negative=\"bad product\"\n",
        "model.predict([negative])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s1xsvB1eRuP",
        "outputId": "1f38e3c5-088b-4923-8fb6-bffa2038de6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10018238, 0.02673815, 0.8730795 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "positive=\"love it\"\n",
        "model.predict([positive])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-colab-shell\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3weh1fLQ8bZ",
        "outputId": "15499030-c988-4823-e8df-10264ccba5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-colab-shell\n",
            "  Downloading google-colab-shell-0.2.tar.gz (4.2 kB)\n",
            "Building wheels for collected packages: google-colab-shell\n",
            "  Building wheel for google-colab-shell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-colab-shell: filename=google_colab_shell-0.2-py3-none-any.whl size=4124 sha256=0c08595064f7dff2aa987d58dcbbc74f5ec35f91aa6bff4e53bb8bb20c6a2a49\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/62/db/d033316a546102d1da60b51a0cc4ddcf0b8c3cc6044469a47b\n",
            "Successfully built google-colab-shell\n",
            "Installing collected packages: google-colab-shell\n",
            "Successfully installed google-colab-shell-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google_colab_shell import getshell\n"
      ],
      "metadata": {
        "id": "Mj_dOhsnRPle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getshell()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "xQ-KVtr0RQ3V",
        "outputId": "0030c259-d86c-49fd-8484-707ef3b35922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!--https://github.com/singhsidhukuldeep/Google-Colab-Shell/-->\n",
              "<!--Using JS/CSS from official sources with backups in-case :)-->\n",
              "<div id=colab_shell></div>\n",
              "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
              "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
              "<script>\n",
              "   $('#colab_shell').terminal(async function(command) {\n",
              "       if (command !== '') {\n",
              "           try {\n",
              "               let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
              "               let out = res.data['application/json'][0]\n",
              "               this.echo(new String(out))\n",
              "           } catch(e) {\n",
              "               this.error(new String(e));\n",
              "           }\n",
              "       } else {\n",
              "           this.echo(\n",
              "             //   '>>Empty Command<<\\n'+\n",
              "             //   'If you can afford use Google Colab Pro'\n",
              "               );\n",
              "       }\n",
              "   }, {\n",
              "       greetings: 'Welcome to Google Colab Shell\\n'+\n",
              "         'If you can afford, please use Google Colab Pro ( https://colab.research.google.com/signup )\\n'+\n",
              "         '⭐ STAR the repo ⭐\\n https://github.com/singhsidhukuldeep/Google-Colab-Shell\\n\\n',\n",
              "       name: 'colab_shell',\n",
              "       height: 400,\n",
              "       prompt: '█$ colab>>\\t'\n",
              "   });\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/amazon.zip /content/amazon_review/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gtl-3FYTABX",
        "outputId": "f25ff5ba-350c-419e-8919-08fdcc194cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/amazon_review/ (stored 0%)\n",
            "  adding: content/amazon_review/1649202398/ (stored 0%)\n",
            "  adding: content/amazon_review/1649202398/assets/ (stored 0%)\n",
            "  adding: content/amazon_review/1649202398/assets/tokens.txt (deflated 43%)\n",
            "  adding: content/amazon_review/1649202398/variables/ (stored 0%)\n",
            "  adding: content/amazon_review/1649202398/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/amazon_review/1649202398/variables/variables.index (deflated 62%)\n",
            "  adding: content/amazon_review/1649202398/saved_model.pb (deflated 86%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2kbStDmeRuP"
      },
      "source": [
        "### Task : TensorFlow Serving with Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zTWa7SReRuP"
      },
      "source": [
        "`docker pull tensorflow/serving`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5pwwUeReRuP"
      },
      "source": [
        "`docker run -p 8500:8500 \\\n",
        "            -p 8501:8501 \\\n",
        "            --mount type=bind,\\\n",
        "            source=amazon_review/,\\\n",
        "            target=/models/amazon_review \\\n",
        "            -e MODEL_NAME=amazon_review \\\n",
        "            -t tensorflow/serving`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts6SHe6weRuQ"
      },
      "source": [
        "#### Perform Model Prediction\n",
        "\n",
        "##### Support for gRPC and REST\n",
        "\n",
        "- TensorFlow Serving supports\n",
        "    - Remote Procedure Protocal (gRPC)\n",
        "    - Representational State Transfer (REST)\n",
        "- Consistent API structures\n",
        "- Server supports both standards simultaneously\n",
        "- Default ports:\n",
        "    - RPC: 8500\n",
        "    - REST: 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NND75SMZUsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb75e23-64f0-4b2b-c09a-91c2aad1c526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tf_serving_rest_client_v2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tf_serving_rest_client_v2.py\n",
        "import json\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "def get_rest_url(model_name, host='192.168.1.103', port='8501', verb='predict', version=None):\n",
        "    \"\"\" generate the URL path\"\"\"\n",
        "    url = \"http://{host}:{port}/v1/models/{model_name}\".format(host=host, port=port, model_name=model_name)\n",
        "    if version:\n",
        "        url += 'versions/{version}'.format(version=version)\n",
        "    url += ':{verb}'.format(verb=verb)\n",
        "    return url\n",
        "\n",
        "\n",
        "def get_model_prediction(model_input, model_name='amazon_review', signature_name='serving_default'):\n",
        "    \"\"\" no error handling at all, just poc\"\"\"\n",
        "\n",
        "    url = get_rest_url(model_name)\n",
        "    #In the row format, inputs are keyed to instances key in the JSON request.\n",
        "    #When there is only one named input, specify the value of instances key to be the value of the input:\n",
        "    data = {\"instances\": [model_input]}\n",
        "    \n",
        "    rv = requests.post(url, data=json.dumps(data))\n",
        "    if rv.status_code != requests.codes.ok:\n",
        "        rv.raise_for_status()\n",
        "    \n",
        "    return rv.json()['predictions']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    print(\"\\nGenerate REST url ...\")\n",
        "    url = get_rest_url(model_name='amazon_review')\n",
        "    print(url)\n",
        "    \n",
        "    while True:\n",
        "        print(\"\\nEnter an Amazon review [:q for Quit]\")\n",
        "        if sys.version_info[0] <= 3:\n",
        "            sentence = input()\n",
        "        if sentence == ':q':\n",
        "            break\n",
        "        model_input = sentence\n",
        "        model_prediction = get_model_prediction(model_input)\n",
        "        print(\"The model predicted ...\")\n",
        "        print(model_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8W7dDY3eRuR"
      },
      "source": [
        "#### Predictions via gRPC\n",
        "\n",
        "More sophisticated client-server connections\n",
        "\n",
        "- Prediction data has to be converted to the Protobuf format\n",
        "- Request types have designated types, e.g. float, int, bytes\n",
        "- Payloads need to be converted to base64\n",
        "- Connect to the server via gRPC stubs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsyewHxVeRuS"
      },
      "source": [
        "#### gRPC vs REST: When to use which API standard\n",
        "\n",
        "- Rest is easy to implement and debug\n",
        "- RPC is more network efficient, smaller payloads\n",
        "- RPC can provide much faster inferences!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKJVOjDlZUvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c34be51-f41b-4e99-d1bd-e9b5e3dca7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tf_serving_grpc_client.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tf_serving_grpc_client.py\n",
        "import sys\n",
        "import grpc\n",
        "from grpc.beta import implementations\n",
        "import tensorflow as tf\n",
        "from tensorflow_serving.apis import predict_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2, get_model_metadata_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "\n",
        "def get_stub(host='127.0.0.1', port='8500'):\n",
        "    channel = grpc.insecure_channel('127.0.0.1:8500') \n",
        "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "    return stub\n",
        "\n",
        "\n",
        "def get_model_prediction(model_input, stub, model_name='amazon_review', signature_name='serving_default'):\n",
        "    \"\"\" no error handling at all, just poc\"\"\"\n",
        "    request = predict_pb2.PredictRequest()\n",
        "    request.model_spec.name = model_name\n",
        "    request.model_spec.signature_name = signature_name\n",
        "    request.inputs['input_input'].CopyFrom(tf.make_tensor_proto(model_input))\n",
        "    response = stub.Predict.future(request, 5.0)  # 5 seconds\n",
        "    return response.result().outputs[\"output\"].float_val\n",
        "\n",
        "\n",
        "def get_model_version(model_name, stub):\n",
        "    request = get_model_metadata_pb2.GetModelMetadataRequest()\n",
        "    request.model_spec.name = 'amazon_review'\n",
        "    request.metadata_field.append(\"signature_def\")\n",
        "    response = stub.GetModelMetadata(request, 10)\n",
        "    # signature of loaded model is available here: response.metadata['signature_def']\n",
        "    return response.model_spec.version.value\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\nCreate RPC connection ...\")\n",
        "    stub = get_stub()\n",
        "    while True:\n",
        "        print(\"\\nEnter an Amazon review [:q for Quit]\")\n",
        "        if sys.version_info[0] <= 3:\n",
        "            sentence = raw_input() if sys.version_info[0] < 3 else input()\n",
        "        if sentence == ':q':\n",
        "            break\n",
        "        model_input = [sentence]\n",
        "        model_prediction = get_model_prediction(model_input, stub)\n",
        "        print(\"The model predicted ...\")\n",
        "        print(model_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TidfRe2VZU39"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA3wNmDSZU66"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TF-Serving-Learner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}